{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* check input and returns in functions\n",
    "* check that what i wrote is accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leonardo Masci, Jeremy Sapienza, Antonio Zappia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this homework is to create a search engine that returns some book suggestions, given an input from the user in the form of words. To achieve this, we first scraped the website Goodreads.com, in its \"best books ever\" section, to get a dataset of 30,000 books. Once we had our dataset, we created increasingly better search algorithms to get to a satisfying result. \n",
    "\n",
    "Finally, in the last exercise we faced a recursive algorithm and its running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since no dataset was provided for this homework, we had to create our own dataset by scraping the given website, which was done in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get the list of books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we had to get the list of all the books we wanted to add to our dataset. This included all the books found in the first 300 pages of the \"best books ever\" section.\n",
    "Therefore, we created a function that scrapes a certain number of pages from an initial url, to extract the url of each of them. The initial url and the following number of pages are given as input, while the resulting urls are stored in a txt file called \"urlpages.txt\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.get_urls(\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Crawl books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we had our txt file containing all the urls, we created a second function that downloads the html of each given url. These htmls are collected in different folders, depending on the corresponding page. Moreover, we added a try and except to be sure that all requests that we could lose will be re-scrape in a second moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.crawl_urls(300,\"urlpages.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after completing this step, we went on to actually parse the given html articles. We will obtain for each html article its article_i.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.get_scraping(\"html_pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and concatening the final dataset for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since running the above mentioned functions took a long time, the three of us split the work among us. So in the end we run another function that returned our distinct outputs as tsv files and combined those three to create the final dataset we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.finaldataset_tsv(html_pages,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset, we can start working on the search engines we are interested in. We will start with a very simple one and work our way towards a more complex one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "df = functions.openMainDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the final dataset to do our operations. Now, we illustrate the main features and we show a piece of dataset belove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>NumberofPages</th>\n",
       "      <th>Published</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>(The Hunger Games #1)</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6413302</td>\n",
       "      <td>172615</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen, Peeta Mellark, Cato (Hunger ...</td>\n",
       "      <td>District 12, Panem, Capitol, Panem, Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>(Harry Potter #5)</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2527001</td>\n",
       "      <td>42768</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870</td>\n",
       "      <td>September 2004 by</td>\n",
       "      <td>Sirius Black, Draco Malfoy, Ron Weasley, Petun...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry, Lo...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>(To Kill a Mockingbird)</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4530963</td>\n",
       "      <td>91866</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch, Atticus Finch, Jem Finch, Arthur ...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3020392</td>\n",
       "      <td>67869</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet, Mrs. Bennet, Jane Bennet, Elizabet...</td>\n",
       "      <td>United Kingdom, Derbyshire, England, England, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>(The Twilight Saga #1)</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4993492</td>\n",
       "      <td>104954</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen, Jacob Black, Laurent, Renee, Be...</td>\n",
       "      <td>Forks, Washington, Phoenix, Arizona, Washingto...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle               bookSeries  \\\n",
       "0                           The Hunger Games    (The Hunger Games #1)   \n",
       "1  Harry Potter and the Order of the Phoenix        (Harry Potter #5)   \n",
       "2                      To Kill a Mockingbird  (To Kill a Mockingbird)   \n",
       "3                        Pride and Prejudice                            \n",
       "4                                   Twilight   (The Twilight Saga #1)   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33      6413302       172615   \n",
       "1     J.K. Rowling         4.50      2527001        42768   \n",
       "2       Harper Lee         4.28      4530963        91866   \n",
       "3      Jane Austen         4.26      3020392        67869   \n",
       "4  Stephenie Meyer         3.60      4993492       104954   \n",
       "\n",
       "                                                Plot NumberofPages  \\\n",
       "0  Could you survive on your own in the wild, wit...           374   \n",
       "1  There is a door at the end of a silent corrido...           870   \n",
       "2  The unforgettable novel of a childhood in a sl...           324   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...           279   \n",
       "4  About three things I was absolutely positive.F...           501   \n",
       "\n",
       "             Published                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen, Peeta Mellark, Cato (Hunger ...   \n",
       "1    September 2004 by  Sirius Black, Draco Malfoy, Ron Weasley, Petun...   \n",
       "2        May 23rd 2006  Scout Finch, Atticus Finch, Jem Finch, Arthur ...   \n",
       "3    October 10th 2000  Mr. Bennet, Mrs. Bennet, Jane Bennet, Elizabet...   \n",
       "4   September 6th 2006  Edward Cullen, Jacob Black, Laurent, Renee, Be...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0          District 12, Panem, Capitol, Panem, Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry, Lo...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom, Derbyshire, England, England, ...   \n",
       "4  Forks, Washington, Phoenix, Arizona, Washingto...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we collect the main features according to the professor requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25442.000000</td>\n",
       "      <td>2.544200e+04</td>\n",
       "      <td>25442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.045976</td>\n",
       "      <td>3.299154e+04</td>\n",
       "      <td>1753.184223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.358727</td>\n",
       "      <td>1.486322e+05</td>\n",
       "      <td>5401.072115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.850000</td>\n",
       "      <td>7.642500e+02</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.050000</td>\n",
       "      <td>5.747000e+03</td>\n",
       "      <td>374.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.240000</td>\n",
       "      <td>2.098875e+04</td>\n",
       "      <td>1333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.104838e+06</td>\n",
       "      <td>172615.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ratingValue   ratingCount    reviewCount\n",
       "count  25442.000000  2.544200e+04   25442.000000\n",
       "mean       4.045976  3.299154e+04    1753.184223\n",
       "std        0.358727  1.486322e+05    5401.072115\n",
       "min        0.000000  0.000000e+00       0.000000\n",
       "25%        3.850000  7.642500e+02      69.000000\n",
       "50%        4.050000  5.747000e+03     374.500000\n",
       "75%        4.240000  2.098875e+04    1333.000000\n",
       "max        5.000000  7.104838e+06  172615.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data and creating the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can procede with the search engines, we need to clean the dataset we have obtained and create a vocabulary. \n",
    "\n",
    "The clean data is needed to apply the search engine, as the input words may not match the ones in our file if processed raw. For this reason, we remove stopwords and punctuation, which do not constitute valuable information, and we apply stemming. This way, we are left with only the root of words, which will make matching in the coming functions that much easier.\n",
    "\n",
    "<font color=\"red\"> WRITE HERE THE MAIN STEPS OF BAG OF WORDS: remove punctution, what is stemming and when we apply this, why remove stop words and so on... </font>\n",
    "\n",
    "The vocabulary is needed for creating the inverted list as a dictionary and at the same time to map each word with its \"term_id_i\". We create this to avoid calculate every time this data structure.\n",
    "\n",
    "at this time cleaning the df_copy dataset in order to have the vocabulary based on \"Plot\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_copy = functions.cleaningDataset(df[0:50].copy()) # useful to obtain the vocabulary for each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the dataset with apposite bag of words method, we create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = functions.createVocabulary(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid calculate again and again the vocabulary save it as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.create_csv(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to receive the user's input, which is then processed the same way as the dataset was so that the matching will be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query string: survival games\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Insert your query string: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the user's query to be sure match with our vocabulary tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surviv', 'game']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanQString = functions.cleanQuery(query)\n",
    "cleanQString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this separated from the rest of vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = functions.open_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the inverted list according to professor requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.inverted_list(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create the new search engine by using the clean query and the inverted list we have found in the previous steps. Now, we show the result according to the professor requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Term_id</th>\n",
       "      <th>Document_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td>term_id_1</td>\n",
       "      <td>['document_0', 'document_7', 'document_31', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surviv</td>\n",
       "      <td>term_id_2</td>\n",
       "      <td>['document_0', 'document_31', 'document_44']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wild</td>\n",
       "      <td>term_id_3</td>\n",
       "      <td>['document_0', 'document_15', 'document_25', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>everi</td>\n",
       "      <td>term_id_4</td>\n",
       "      <td>['document_0', 'document_10', 'document_12', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>term_id_5</td>\n",
       "      <td>['document_0', 'document_3', 'document_5', 'do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>bone</td>\n",
       "      <td>term_id_2018</td>\n",
       "      <td>['document_49']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>succe</td>\n",
       "      <td>term_id_2019</td>\n",
       "      <td>['document_49']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>miracul</td>\n",
       "      <td>term_id_2020</td>\n",
       "      <td>['document_49']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>build</td>\n",
       "      <td>term_id_2021</td>\n",
       "      <td>['document_49']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>joy</td>\n",
       "      <td>term_id_2022</td>\n",
       "      <td>['document_49']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word       Term_id                                      Document_List\n",
       "0       could     term_id_1  ['document_0', 'document_7', 'document_31', 'd...\n",
       "1      surviv     term_id_2       ['document_0', 'document_31', 'document_44']\n",
       "2        wild     term_id_3  ['document_0', 'document_15', 'document_25', '...\n",
       "3       everi     term_id_4  ['document_0', 'document_10', 'document_12', '...\n",
       "4         one     term_id_5  ['document_0', 'document_3', 'document_5', 'do...\n",
       "...       ...           ...                                                ...\n",
       "2017     bone  term_id_2018                                    ['document_49']\n",
       "2018    succe  term_id_2019                                    ['document_49']\n",
       "2019  miracul  term_id_2020                                    ['document_49']\n",
       "2020    build  term_id_2021                                    ['document_49']\n",
       "2021      joy  term_id_2022                                    ['document_49']\n",
       "\n",
       "[2022 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bookTitle                                               Plot  \\\n",
       "0  The Hunger Games  Could you survive on your own in the wild, wit...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.search_engine1(cleanQString, 'inv_lst.csv', vocabulary, df_copy, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining the new search engine, we have to update our inverted list according to professors request, we want to have the pair list, for each term that we have into our vocabulary, the document where the term is present and the relative tf_idf score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> EXPLAIN WHERE DO YOU EXTRACT AND OBTAIN THE TF_IDF... EXPLAIN THE Term Frequency and the IDF... then the TF_IDF!! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_lst2 = functions.new_inv_lst('inv_lst.csv', vocabulary, df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we get the user's input and we clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query string: survival games\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Insert your query string: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surviv', 'game']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanQString = functions.cleanQuery(query)\n",
    "cleanQString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHY NEW_DF? .... <font color=\"red\"> SHOW UP the new search engine according to the requests!... </font>\n",
    "\n",
    "We can now run the second search engine, which is an improved version of the previous one as it takes into consideration not only the number of words in the query that are found in the plots, but also how often those words are mentioned. This makes the search engine more accurate in identifying books that are relevant given a certain query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = functions.search_engine2(df_copy, df, inv_lst2, vocabulary, cleanQString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we show the final dataset returned by our search_engine2() function according to the professor requests.. we can see k top documents sorted by similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>Alternate Cover Edition ISBN: 0743273567 (ISBN...</td>\n",
       "      <td>https://www.goodreads.com/book/show/4671.The_G...</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Wrinkle in Time</td>\n",
       "      <td>It was a dark and stormy night.Out of this wil...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33574273-a...</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>Here is the first volume in George R. R. Marti...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13496.A_Ga...</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anne of Green Gables</td>\n",
       "      <td>As soon as Anne Shirley arrives at the snug wh...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8127.Anne_...</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle  \\\n",
       "0  Harry Potter and the Order of the Phoenix   \n",
       "1                           The Great Gatsby   \n",
       "2                          A Wrinkle in Time   \n",
       "3                          A Game of Thrones   \n",
       "4                       Anne of Green Gables   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  There is a door at the end of a silent corrido...   \n",
       "1  Alternate Cover Edition ISBN: 0743273567 (ISBN...   \n",
       "2  It was a dark and stormy night.Out of this wil...   \n",
       "3  Here is the first volume in George R. R. Marti...   \n",
       "4  As soon as Anne Shirley arrives at the snug wh...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/2.Harry_Po...        0.09  \n",
       "1  https://www.goodreads.com/book/show/4671.The_G...        0.03  \n",
       "2  https://www.goodreads.com/book/show/33574273-a...        0.02  \n",
       "3  https://www.goodreads.com/book/show/13496.A_Ga...        0.02  \n",
       "4  https://www.goodreads.com/book/show/8127.Anne_...        0.01  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define a new score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to improve again on our search engine, this time by taking into account multiple variables. \n",
    "* similarity score also in book title and author (year it was published, series, characters and setting)\n",
    "* we could define a \"popularity\" score that takes into account the average rating and the number of reviews\n",
    "* we then could combine the two to create the final score and sorting order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
